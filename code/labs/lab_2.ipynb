{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 - Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import pandas as pd\n",
    "\n",
    "# \\u00a7 275.0-2 expressions\n",
    "true_values = [\n",
    "    {\"doc_id\": \"ยง 275.0-2_P1\", \"id\": 1, \"expression\": \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\"},\n",
    "    {\"doc_id\": \"ยง 275.0-2_P1\", \"id\": 2, \"A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\",\n",
    "    \"If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\",\n",
    "    \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"Managing agent means any person, including a trustee, who directs or manages, or who participates in directing or managing, the affairs of any unincorporated organization or association other than a partnership.\",\n",
    "    \"Non-resident means an individual who resides in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a corporation that is incorporated in or that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a partnership or other unincorporated organization or association that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Principal office and place of business has the same meaning as in \\u00a7 275.203A-3(c) of this chapter.\"\n",
    "]\n",
    "\n",
    "# List of suspect domains to check for potential impersonation\n",
    "pred_values = [\n",
    "    \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\",\n",
    "    \"A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\",\n",
    "    \"If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\",\n",
    "    \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"Managing agent means any person, including a trustee, who directs or manages, or who participates in directing or managing, the affairs of any unincorporated organization or association other than a partnership.\",\n",
    "    \"Non-resident means an individual who resides in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a corporation that is incorporated in or that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a partnership or other unincorporated organization or association that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Principal office and place of business has the same meaning as in \\u00a7 275.203A-3(c) of this chapter.\",\n",
    "]\n",
    "\n",
    "# Function to check the similarity between true and pred expression\n",
    "def check_for_expressions_mililarity(true_list, pred_list, threshold=0.7):\n",
    "    results = []\n",
    "    for pred in pred_list:\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for true_item in true_list:\n",
    "            # Calculate the similarity score using the Levenshtein distance\n",
    "            score = jellyfish.levenshtein_distance(pred, true_item)\n",
    "            similarity_score = 1 - (score / max(len(pred), len(true_item)))  # Normalizing to a similarity score\n",
    "            \n",
    "            if similarity_score > best_score:\n",
    "                best_score = similarity_score\n",
    "                best_match = true_item\n",
    "        results.append((pred, best_match, best_score))\n",
    "    return results\n",
    "\n",
    "# Check for potential domain impersonations\n",
    "similarity_results = check_for_expressions_mililarity(true_values, pred_values)\n",
    "\n",
    "# Building dataframe\n",
    "df_results = pd.DataFrame(similarity_results, columns=[\"pred_expression\", \"true_expression\", \"similarity_score\"])\n",
    "\n",
    "# Adding Color Coding to \"Similarity Score\" Column\n",
    "def highlight_similarity(val):\n",
    "    color = 'green' if val >= 0.9 else 'red'  \n",
    "    return f'background-color: {color}'\n",
    "styled_df = df_results.style.applymap(highlight_similarity, subset=[\"similarity_score\"])\n",
    "styled_df.set_table_attributes('style=\"width: 100%; border: 1px solid black;\"')\n",
    "styled_df.set_properties(**{'border': '1px solid black'})\n",
    "\n",
    "\n",
    "# Display the final DataFrame\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the id fields from both pred_list and true_list, we can enhance your code to analyze how often the pred_id matches the true_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to group expressions by doc_id\n",
    "def group_expressions_by_doc_id(expressions_list, is_pred=False):\n",
    "    doc_id_map = defaultdict(list)\n",
    "    for item in expressions_list:\n",
    "        doc_id = item['doc_id']\n",
    "        if is_pred:\n",
    "            # Include filename, id, and classification for pred_list items\n",
    "            expression_info = {\n",
    "                'id': item['id'],\n",
    "                'expression': item['expression'],\n",
    "                'classification_pred': item.get('classification', None),\n",
    "                'filename_pred': item['filename']\n",
    "            }\n",
    "        else:\n",
    "            # Include id and classification for true_list items\n",
    "            expression_info = {\n",
    "                'id': item['id'],\n",
    "                'expression': item['expression'],\n",
    "                'classification_true': item.get('classification', None)\n",
    "            }\n",
    "        doc_id_map[doc_id].append(expression_info)\n",
    "    return doc_id_map\n",
    "\n",
    "# Function to check the similarity between true and pred expressions grouped by doc_id\n",
    "def check_for_expressions_similarity(true_list, pred_list, threshold=0.7):\n",
    "    # Build mappings from doc_id to list of expressions\n",
    "    true_expressions_by_doc_id = group_expressions_by_doc_id(true_list)\n",
    "    pred_expressions_by_doc_id = group_expressions_by_doc_id(pred_list, is_pred=True)\n",
    "\n",
    "    results = []\n",
    "    all_doc_ids = set(true_expressions_by_doc_id.keys()).union(pred_expressions_by_doc_id.keys())\n",
    "\n",
    "    for doc_id in all_doc_ids:\n",
    "        true_expressions = true_expressions_by_doc_id.get(doc_id, [])\n",
    "        pred_expressions = pred_expressions_by_doc_id.get(doc_id, [])\n",
    "\n",
    "        for pred_item in pred_expressions:\n",
    "            pred_expr = pred_item['expression']\n",
    "            pred_id = pred_item['id']\n",
    "            classification_pred = pred_item.get('classification_pred', None)\n",
    "            filename_pred = pred_item['filename_pred']\n",
    "            best_match = None\n",
    "            best_score = 0\n",
    "            best_true_id = None\n",
    "            classification_true = None\n",
    "            for true_item in true_expressions:\n",
    "                true_expr = true_item['expression']\n",
    "                true_id = true_item['id']\n",
    "                # Calculate the similarity score using the Levenshtein distance\n",
    "                score = jellyfish.levenshtein_distance(pred_expr, true_expr)\n",
    "                similarity_score = 1 - (score / max(len(pred_expr), len(true_expr)))  # Normalize to a similarity score\n",
    "\n",
    "                if similarity_score > best_score:\n",
    "                    best_score = similarity_score\n",
    "                    best_match = true_expr\n",
    "                    best_true_id = true_id\n",
    "                    classification_true = true_item.get('classification_true', None)\n",
    "            results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"pred_id\": pred_id,\n",
    "                \"true_id\": best_true_id,\n",
    "                \"classification_pred\": classification_pred,\n",
    "                \"classification_true\": classification_true,\n",
    "                \"filename_pred\": filename_pred,\n",
    "                \"pred_expression\": pred_expr,\n",
    "                \"true_expression\": best_match,\n",
    "                \"similarity_score\": best_score\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Use the function with your data\n",
    "similarity_results = check_for_expressions_similarity(true_elements, pred_elements)\n",
    "\n",
    "# Build the dataframe\n",
    "df_results = pd.DataFrame(similarity_results)\n",
    "\n",
    "# Add a column to indicate whether the pred_id matches the true_id\n",
    "df_results['id_match'] = df_results['pred_id'] == df_results['true_id']\n",
    "\n",
    "# Calculate the number and percentage of matches\n",
    "total_matches = df_results['id_match'].sum()\n",
    "total_comparisons = len(df_results)\n",
    "match_percentage = (total_matches / total_comparisons) * 100\n",
    "\n",
    "print(f\"Total Matches: {total_matches}\")\n",
    "print(f\"Total Comparisons: {total_comparisons}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "# Create a confusion matrix for ID matching\n",
    "# We'll label matches as 'match' and mismatches as 'mismatch'\n",
    "df_results['id_match_label'] = df_results['id_match'].map({True: 'match', False: 'mismatch'})\n",
    "\n",
    "# Generate confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Prepare the data\n",
    "y_true = df_results['id_match_label']  # Since we're comparing IDs, y_true and y_pred are the same\n",
    "y_pred = df_results['id_match_label']\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = ['match', 'mismatch']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title('ID Match Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, labels=labels, digits=4)\n",
    "print(\"Classification Report for ID Matching:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for labs\n",
    "import sys\n",
    "sys.path.append(r'../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party libraries\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "import spacy\n",
    "from slugify import slugify\n",
    "\n",
    "# Franz AllegroGraph (AG) imports\n",
    "from franz.openrdf.connect import ag_connect\n",
    "from franz.openrdf.repository.repository import RepositoryConnection\n",
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "# Local application/library-specific imports\n",
    "import checkpoint.main as checkpoint\n",
    "from checkpoint.main import (\n",
    "    restore_checkpoint,\n",
    "    DocumentProcessor,\n",
    ")\n",
    "import configuration.main as configuration\n",
    "import logging_setup.main as logging_setup\n",
    "\n",
    "DEV_MODE = True\n",
    "\n",
    "if DEV_MODE:\n",
    "    # Development mode\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(configuration)\n",
    "    importlib.reload(logging_setup)\n",
    "    importlib.reload(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 20:50:52 - INFO - Logging is set up with daily rotation.\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "DEFAULT_CONFIG_FILE=\"../config.yaml\"\n",
    "config = configuration.load_config(DEFAULT_CONFIG_FILE)\n",
    "\n",
    "logger = logging_setup.setting_logging(config[\"DEFAULT_LOG_DIR\"], config[\"LOG_LEVEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_kg(conn: RepositoryConnection, signifier: str, kg: str, vector_db: str, exact: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Queries the knowledge graph to retrieve similar terms to the given term.\n",
    "\n",
    "    Args:\n",
    "        conn (RepositoryConnection): The AllegroGraph repository connection.\n",
    "        term (str): The term to search for similar terms in the knowledge graph.\n",
    "        kg (str): The name of the knowledge graph to query.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries containing information about similar terms,\n",
    "        including URIs, scores, definitions, and related predicates.\n",
    "    \"\"\"\n",
    "\n",
    "    if kg not in {config[\"FIBO_GRAPH\"], config[\"CFR_SBVR_GRAPH\"]}:\n",
    "        raise ValueError(f\"Unsupported knowledge graph: {kg}\")\n",
    "\n",
    "    query_string_close = f\"\"\"\n",
    "PREFIX llm: <http://franz.com/ns/allegrograph/8.0.0/llm/>\n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
    "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
    "\n",
    "SELECT ?uri (xsd:decimal(?score) as ?score_percent) ?s ?p ?definition\n",
    "FROM {kg}\n",
    "WHERE {{\n",
    "    (?uri ?score ?originalText ?p) llm:nearestNeighbor (\"{signifier}\" \"{vector_db}\" 5 {config[\"SIMILARITY_THRESHOLD\"]}) .\n",
    "    ?s ?p ?originalText .\n",
    "\n",
    "    OPTIONAL {{ ?s skos:definition ?definition . }}\n",
    "    OPTIONAL {{ ?s sbvr:Statement ?definition . }}\n",
    "}}\n",
    "ORDER BY DESC(?score)\n",
    "    \"\"\"\n",
    "\n",
    "    query_string_exact = f\"\"\"\n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX fro-cfr: <http://cfr2sbvr.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT (\"https://spec.edmcouncil.org/fibo\"^^xsd:anyUri as ?uri) (xsd:decimal(100) as ?score_percent) ?s (rdfs:label as ?p) ?definition ?originalText\n",
    "FROM NAMED fibo:FIBO_Graph\n",
    "WHERE {{\n",
    "  GRAPH ?g {{\n",
    "    ?s a ?type ;\n",
    "    skos:definition ?definition ;\n",
    "    (rdfs:label | skos:prefLabel) ?originalText .\n",
    "    \n",
    "    FILTER(?type IN (owl:Class, owl:NamedIndividual))\n",
    "    FILTER(LCASE(STR(?originalText)) = \"{signifier}\")\n",
    "  }}\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    if exact:\n",
    "        query_string = query_string_exact\n",
    "    else:\n",
    "        query_string = query_string_close\n",
    "\n",
    "    logger.debug(f\"SPARQL Query: {query_string}\")\n",
    "\n",
    "    tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "\n",
    "    try:\n",
    "        result = tuple_query.evaluate()\n",
    "        logger.debug(f\"Result metadata: {result.metadata}\")\n",
    "\n",
    "        with result:\n",
    "            similar_signifiers = [\n",
    "                {\n",
    "                    \"uri\": str(binding.getValue(\"uri\")),\n",
    "                    \"score_percent\": Decimal(binding.getValue(\"score_percent\").getLabel()),\n",
    "                    \"located_signifier_uri\": str(binding.getValue(\"s\")),\n",
    "                    \"located_signifier_uri_local_name\": binding.getValue(\"s\").getLocalName(),\n",
    "                    \"located_signifier_predicate\": str(binding.getValue(\"p\")),\n",
    "                    \"definition\": str(binding.getValue(\"definition\"))\n",
    "                }\n",
    "                for binding in result\n",
    "            ]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error evaluating SPARQL query: {e}\")\n",
    "        raise\n",
    "\n",
    "    logger.info(f\"Found {len(similar_signifiers)} similar signifier(s) for '{signifier}' on {kg}.\")\n",
    "\n",
    "    return similar_signifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fibo:FIBO_Graph', 'fibo-glossary-3m-vec', 0.85)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fibo-glossary-3m-vec\n",
    "config[\"FIBO_GRAPH\"], config[\"FIBO_GRAPH_VECTOR_STORE\"], config[\"SIMILARITY_THRESHOLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_signifiers(conn: RepositoryConnection, signifier: str) -> Tuple[list]:\n",
    "    \"\"\"\n",
    "    Get similar signifiers for a given signifier.\n",
    "\n",
    "    Args:\n",
    "        conn (allegrograph.AllegroGraphConnection): An AllegroGraph connection object.\n",
    "        signifier (str): The signifier to search for.\n",
    "\n",
    "    Returns:\n",
    "        list (Tuple[list]): A list of exact and close matches for the signifier.\n",
    "    \"\"\"\n",
    "    fibo_exact =  get_from_kg(conn, signifier, config[\"FIBO_GRAPH\"], config[\"FIBO_GRAPH_VECTOR_STORE\"], True)\n",
    "    fibo_similarity =  get_from_kg(conn, signifier, config[\"FIBO_GRAPH\"], config[\"FIBO_GRAPH_VECTOR_STORE\"], False)\n",
    "    cfr_sbvr_similarity = get_from_kg(conn, signifier, config[\"CFR_SBVR_GRAPH\"], config[\"CFR_SBVR_GRAPH_VECTOR_STORE\"], False)\n",
    "\n",
    "    exact_match = []\n",
    "    close_match = []\n",
    "\n",
    "    for item in fibo_similarity:\n",
    "        logger.info(f\"{item=}\")\n",
    "        close_match.append(item.get(\"located_signifier_uri\"))\n",
    "\n",
    "    for item in fibo_exact:\n",
    "        logger.info(f\"{item=}\")\n",
    "        exact_match.append(item.get(\"located_signifier_uri\"))\n",
    "\n",
    "    for item in cfr_sbvr_similarity:\n",
    "        close_match.append(item.get(\"located_signifier_uri\"))\n",
    "\n",
    "    logger.info(f\"Found {len(exact_match)} exact matche(s) and {len(close_match)} close matche(s) for '{signifier}'.\")\n",
    "\n",
    "    return exact_match, close_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 20:05:54 - INFO - Connected to AllegroGraph: ALLEGROGRAPH_LOCAL\n"
     ]
    }
   ],
   "source": [
    "hosting = config[\"ALLEGROGRAPH_HOSTING\"]\n",
    "\n",
    "conn = ag_connect(\n",
    "    repo=config[hosting][\"REPO\"],\n",
    "    catalog=config[hosting][\"CATALOG\"],\n",
    "    host=config[hosting][\"HOST\"],\n",
    "    port=config[hosting][\"PORT\"],\n",
    "    user=config[hosting][\"USER\"],\n",
    "    password=config[hosting][\"PASSWORD\"],\n",
    ")\n",
    "\n",
    "logger.info(f\"Connected to AllegroGraph: {hosting}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 20:54:53 - INFO - Found 1 similar signifier(s) for 'person' on fibo:FIBO_Graph.\n",
      "2025-03-05 20:54:55 - INFO - Found 4 similar signifier(s) for 'person' on fibo:FIBO_Graph.\n",
      "2025-03-05 20:54:55 - INFO - Found 0 similar signifier(s) for 'person' on cfr-sbvr:CFR_SBVR.\n",
      "2025-03-05 20:54:55 - INFO - item={'uri': '<http://franz.com/vdb/id/1409>', 'score_percent': Decimal('0.8905864953994751'), 'located_signifier_uri': '<https://spec.edmcouncil.org/fibo/ontology/FND/AgentsAndPeople/People/PersonName>', 'located_signifier_uri_local_name': 'PersonName', 'located_signifier_predicate': '<http://www.w3.org/2000/01/rdf-schema#label>', 'definition': '\"designation by which someone is known in some context\"'}\n",
      "2025-03-05 20:54:55 - INFO - item={'uri': '<http://franz.com/vdb/id/802>', 'score_percent': Decimal('0.8800179958343506'), 'located_signifier_uri': '<https://spec.edmcouncil.org/fibo/ontology/FND/ProductsAndServices/ProductsAndServices/Consumer>', 'located_signifier_uri_local_name': 'Consumer', 'located_signifier_predicate': '<http://www.w3.org/2000/01/rdf-schema#label>', 'definition': '\"party that utilizes economic goods or services, typically for personal, family, or household purposes\"'}\n",
      "2025-03-05 20:54:55 - INFO - item={'uri': '<http://franz.com/vdb/id/805>', 'score_percent': Decimal('0.8721467852592468'), 'located_signifier_uri': '<https://spec.edmcouncil.org/fibo/ontology/FND/ProductsAndServices/ProductsAndServices/Client>', 'located_signifier_uri_local_name': 'Client', 'located_signifier_predicate': '<http://www.w3.org/2000/01/rdf-schema#label>', 'definition': '\"party that purchases professional services from, or has a formal relationship to purchase services from another party\"'}\n",
      "2025-03-05 20:54:55 - INFO - item={'uri': '<http://franz.com/vdb/id/1238>', 'score_percent': Decimal('0.8721261024475098'), 'located_signifier_uri': '<https://spec.edmcouncil.org/fibo/ontology/FND/Organizations/FormalOrganizations/Employee>', 'located_signifier_uri_local_name': 'Employee', 'located_signifier_predicate': '<http://www.w3.org/2000/01/rdf-schema#label>', 'definition': '\"person in the service of another under any contract of hire, express or implied, oral or written, where the employer has the right to control and direct that person in the material details of how the work is to be performed\"'}\n",
      "2025-03-05 20:54:55 - INFO - item={'uri': '\"https://spec.edmcouncil.org/fibo\"^^<http://www.w3.org/2001/XMLSchema#anyUri>', 'score_percent': Decimal('100.0'), 'located_signifier_uri': '<https://spec.edmcouncil.org/fibo/ontology/FND/AgentsAndPeople/People/Person>', 'located_signifier_uri_local_name': 'Person', 'located_signifier_predicate': '<http://www.w3.org/2000/01/rdf-schema#label>', 'definition': '\"individual human being, with consciousness of self\"'}\n",
      "2025-03-05 20:54:55 - INFO - Found 1 exact matche(s) and 4 close matche(s) for 'person'.\n"
     ]
    }
   ],
   "source": [
    "exact_match, close_match = get_similar_signifiers(conn, \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<https://spec.edmcouncil.org/fibo/ontology/FND/AgentsAndPeople/People/Person>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<https://spec.edmcouncil.org/fibo/ontology/FND/AgentsAndPeople/People/PersonName>',\n",
       " '<https://spec.edmcouncil.org/fibo/ontology/FND/ProductsAndServices/ProductsAndServices/Consumer>',\n",
       " '<https://spec.edmcouncil.org/fibo/ontology/FND/ProductsAndServices/ProductsAndServices/Client>',\n",
       " '<https://spec.edmcouncil.org/fibo/ontology/FND/Organizations/FormalOrganizations/Employee>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity search\n",
    "\n",
    "```sparql\n",
    "PREFIX llm: <http://franz.com/ns/allegrograph/8.0.0/llm/> \n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX fro-cfr: <http://cfr2sbvr.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "select ?uri ?score (xsd:decimal(?score)*100 as ?score_percent) ?originalText ?definition\n",
    "FROM fibo:FIBO_Graph\n",
    "{\n",
    "  (?uri ?score ?originalText) llm:nearestNeighbor (\"employee\" \"test1-fibo\" 5 0.9) .\n",
    "\n",
    "  ?term a owl:Class ;\n",
    "    skos:definition ?definition ;\n",
    "    ?o ?originalText .\n",
    "}\n",
    "ORDER BY DESC(?score)\n",
    "```\n",
    "\n",
    "fibo-terms-definition\n",
    "\n",
    "```sparql\n",
    "# This PREFIX causes the default graph of the dataset to include\n",
    "# only triples that are not in a named graph.\n",
    "# Otherwise, the default graph will include every triple.\n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX fro-cfr: <http://cfr2sbvr.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "\n",
    "# View quads\n",
    "SELECT ?term ?definition\n",
    "#FROM fro-cfr:Code_Federal_Regulations_Graph\n",
    "FROM fibo:FIBO_Graph\n",
    "WHERE { \n",
    "  ?term a owl:Class ;\n",
    "  skos:definition ?definition .\n",
    "}\n",
    "```\n",
    "\n",
    "Qde embeddings\n",
    "\n",
    "```sparkl\n",
    "# Definition\n",
    "select (COUNT(?s) AS ?qty_emb)\n",
    "where {\n",
    "  ?s <http://franz.com/vdb/gen/embedding> ?o . \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AllegroGraph Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the src (modules) directory to the path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import configuration.main as configuration  # noqa: E402configuration.main as configuration\n",
    "\n",
    "config = configuration.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import os\n",
    "\n",
    "# Ensure the ../logs directory exists\n",
    "# log_directory = os.path.join(os.getcwd(), config[\"DEFAULT_LOG_DIR\"])\n",
    "# os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "# # Path for the log file\n",
    "# log_file_path = os.path.join(log_directory, 'application.log')\n",
    "\n",
    "# # Set up TimedRotatingFileHandler to rotate logs every day\n",
    "# file_handler = TimedRotatingFileHandler(\n",
    "#     log_file_path, when=\"midnight\", interval=1, backupCount=0  # Rotate every midnight, keep all backups\n",
    "# )\n",
    "\n",
    "# # Set the file handler's log format\n",
    "# file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=config[\"LOG_LEVEL\"],  # Set to the desired log level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Console log format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',  # Custom date format\n",
    "    handlers=[\n",
    "        #file_handler,  # Log to the rotating file in ../logs\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Log a test message to verify\n",
    "#logger.info(\"Logging is set up with daily rotation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'https://{config[\"ALLEGROGRAPH\"][\"HOST\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "REPO= \"actors\"\n",
    "CATALOG= \"root\"\n",
    "HOST= \"ag1eawvuu0p3zv35.allegrograph.cloud\" # for AllegroGraph cloud\n",
    "PORT= 443 # for AllegroGraph cloud\n",
    "USER= \"admin\" # for AllegroGraph cloud\n",
    "PASSWORD= \"\"  # Replace with your password\n",
    "HOME_DIR= \"/home/adsantos/agraph-8.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ag_connect(repo=REPO, catalog=config[\"ALLEGROGRAPH\"][\"CATALOG\"],\n",
    "                host=config[\"ALLEGROGRAPH\"][\"HOST\"], port=config[\"ALLEGROGRAPH\"][\"PORT\"],\n",
    "                protocol=\"http\",\n",
    "                user=config[\"ALLEGROGRAPH\"][\"USER\"], password=config[\"ALLEGROGRAPH\"][\"PASSWORD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\"\"\")\n",
    "query_string = \"SELECT ?s ?p ?o { ?s ?p ?o . } LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "result = tuple_query.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with result:\n",
    "   for binding_set in result:\n",
    "        s = binding_set.getValue(\"s\")\n",
    "        p = binding_set.getValue(\"p\")\n",
    "        o = binding_set.getValue(\"o\")\n",
    "        print(\"%s %s %s\" % (s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.repository.repository import Repository\n",
    "\n",
    "server = AllegroGraphServer(host=config[\"ALLEGROGRAPH\"][\"HOST\"], port=config[\"ALLEGROGRAPH\"][\"PORT\"],\n",
    "                            user=config[\"ALLEGROGRAPH\"][\"USER\"], password=config[\"ALLEGROGRAPH\"][\"PASSWORD\"],\n",
    "                            repo=config[\"ALLEGROGRAPH\"][\"REPO\"])\n",
    "\n",
    "print(f\"Available catalogs: {server.listCatalogs()}\")\n",
    "\n",
    "catalog = server.openCatalog('root')\n",
    "\n",
    "print(f\"Available repositories: {catalog.listRepositories()}\")\n",
    "\n",
    "myRepository = catalog.getRepository(\"actors\", Repository.ACCESS)\n",
    "\n",
    "print(f\"Available databases: {myRepository.getDatabaseName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround SSL problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stunnel for SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing agraph_stunnel.conf\n"
     ]
    }
   ],
   "source": [
    "%%writefile agraph_stunnel.conf\n",
    "\n",
    "[allegrograph_proxy]\n",
    "client = yes\n",
    "accept = 127.0.0.1:8443\n",
    "connect = ag1eawvuu0p3zv35.allegrograph.cloud:443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for adsantos: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S stunnel agraph_stunnel.conf\" #can be any command but don't forget -S as it enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command)) # Start stunnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ag_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_cloud = ag_connect(repo=REPO, catalog=CATALOG,\n",
    "                host=\"localhost\", port=8443,\n",
    "                protocol=\"http\",\n",
    "                user=USER, password=PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_query = conn_cloud.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "result = tuple_query.evaluate()\n",
    "\n",
    "with result:\n",
    "   for binding_set in result:\n",
    "        s = binding_set.getValue(\"s\")\n",
    "        p = binding_set.getValue(\"p\")\n",
    "        o = binding_set.getValue(\"o\")\n",
    "        print(\"%s %s %s\" % (s, p, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.repository.repository import Repository\n",
    "\n",
    "server = AllegroGraphServer(host=\"localhost\", port=8443,\n",
    "                            user=USER, password=PASSWORD, \n",
    "                            protocol=\"http\")\n",
    "\n",
    "print(f\"Available catalogs: {server.listCatalogs()}\")\n",
    "\n",
    "catalog = server.openCatalog('root')\n",
    "\n",
    "print(f\"Available repositories: {catalog.listRepositories()}\")\n",
    "\n",
    "myRepository = catalog.getRepository(\"actors\", Repository.ACCESS)\n",
    "\n",
    "print(f\"Available databases: {myRepository.getDatabaseName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_cloud.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S kill $(ps aux | grep 'stunnel agraph_stunnel.conf' | awk '{print $2}')\" \n",
    "os.system('echo %s | %s' % (password, command)) # Start stunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_num = \"ยง 275.0-7\"\n",
    "# logger.info(get_section_from_kg(conn, section_num=section_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
